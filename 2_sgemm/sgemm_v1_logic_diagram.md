# SGEMM V1 - 共享内存版本 计算逻辑图

## 核心算法

**目标**：使用共享内存优化矩阵乘法 C = A × B，减少全局内存访问次数

## 假设参数
- 矩阵A: 4×4, 矩阵B: 4×4, 矩阵C: 4×4  
- BLOCK_SIZE = 2 (为了简化图示)
- K = 4 (K维度一次性加载到共享内存)

## 共享内存布局

### 共享内存声明
```
__shared__ float A_shared[BLOCK_SIZE][K];     // A_shared[2][4]
__shared__ float B_shared[K][BLOCK_SIZE];     // B_shared[4][2]
```

### 内存映射关系
```
A_shared布局:               B_shared布局:
┌─────┬─────┬─────┬─────┐   ┌─────┬─────┐
│A[0,0]│A[0,1]│A[0,2]│A[0,3]│   │B[0,0]│B[0,1]│
├─────┼─────┼─────┼─────┤   ├─────┼─────┤
│A[1,0]│A[1,1]│A[1,2]│A[1,3]│   │B[1,0]│B[1,1]│
└─────┴─────┴─────┴─────┘   ├─────┼─────┤
                           │B[2,0]│B[2,1]│
                           ├─────┼─────┤
                           │B[3,0]│B[3,1]│
                           └─────┴─────┘
```

## 数据加载过程详解

### 阶段1: 并行数据加载

#### Block(0,0)的数据加载 (计算C[0:2][0:2])
```
线程分工:
T(0,0): 加载A[0][0→3] → A_shared[0][0→3], 加载B[0→3][0] → B_shared[0→3][0]
T(0,1): 加载A[0][0→3] → A_shared[0][0→3], 加载B[0→3][1] → B_shared[0→3][1]  
T(1,0): 加载A[1][0→3] → A_shared[1][0→3], 加载B[0→3][0] → B_shared[0→3][0]
T(1,1): 加载A[1][0→3] → A_shared[1][0→3], 加载B[0→3][1] → B_shared[0→3][1]

加载后的共享内存:
A_shared:                   B_shared:
┌─────┬─────┬─────┬─────┐   ┌─────┬─────┐
│A[0,0]│A[0,1]│A[0,2]│A[0,3]│   │B[0,0]│B[0,1]│
├─────┼─────┼─────┼─────┤   ├─────┼─────┤
│A[1,0]│A[1,1]│A[1,2]│A[1,3]│   │B[1,0]│B[1,1]│
└─────┴─────┴─────┴─────┘   ├─────┼─────┤
                           │B[2,0]│B[2,1]│
                           ├─────┼─────┤
                           │B[3,0]│B[3,1]│
                           └─────┴─────┘
```

### 阶段2: 同步等待
```
__syncthreads(); // 确保所有线程完成数据加载
```

### 阶段3: 并行计算

#### 以计算C[0][0]为例 (由T(0,0)负责)
```
计算过程:
k=0: temp += A_shared[0][0] * B_shared[0][0]
k=1: temp += A_shared[0][1] * B_shared[1][0]  
k=2: temp += A_shared[0][2] * B_shared[2][0]
k=3: temp += A_shared[0][3] * B_shared[3][0]

结果: C[0][0] = temp
```

#### 所有线程并行计算
```
T(0,0) → C[0][0]: A_shared[0][:] · B_shared[:][0]
T(0,1) → C[0][1]: A_shared[0][:] · B_shared[:][1]
T(1,0) → C[1][0]: A_shared[1][:] · B_shared[:][0]  
T(1,1) → C[1][1]: A_shared[1][:] · B_shared[:][1]
```

## 内存访问模式对比

### V0版本 vs V1版本
```
V0 (全局内存):
每计算一个C元素需要: 2K次全局内存读取
总全局内存访问: 2×M×N×K 次

V1 (共享内存):
数据加载阶段: M×K + K×N 次全局内存读取
计算阶段: 2K次共享内存读取 (每个C元素)
总全局内存访问: M×K + K×N 次
总共享内存访问: 2×M×N×K 次
```

### 数据复用分析
```
V0版本数据复用:
A[i][j] 被读取 N 次 (每列计算都需要)
B[i][j] 被读取 M 次 (每行计算都需要)

V1版本数据复用:  
A[i][j] 在全局内存只读取 1 次，在共享内存被复用 BLOCK_SIZE 次
B[i][j] 在全局内存只读取 1 次，在共享内存被复用 BLOCK_SIZE 次
```

## 算法特点分析

### 执行流程
```
1. 分配共享内存存储A和B的子矩阵
2. 并行加载：每个线程负责加载部分数据到共享内存
3. 同步等待：确保所有数据加载完成
4. 并行计算：从共享内存读取数据进行矩阵乘法
5. 写入结果到全局内存
```

### 性能特点

#### 优点
- **减少全局内存访问**: 数据复用，多个线程共享同一份数据
- **提高内存带宽利用率**: 合并内存访问模式  
- **降低访问延迟**: 共享内存访问延迟远低于全局内存

#### 缺点
- **实现复杂度增加**: 需要管理共享内存和线程同步
- **K维度限制**: 当K值很大时，共享内存容量不足
- **边界处理复杂**: 需要处理矩阵边界情况

### 内存访问分析

```
性能提升统计:
┌─────────────────┬──────────┬───────────┬──────────────┐
│    访问类型     │  V0版本  │  V1版本   │   改进幅度   │
├─────────────────┼──────────┼───────────┼──────────────┤
│ 全局内存读取    │ 2×M×N×K  │ M×K+K×N   │ 减少约K倍    │
│ 共享内存读取    │    0     │ 2×M×N×K   │ 新增低延迟访问│
│ 内存延迟       │ ~400周期  │ ~20周期   │ 降低20倍     │
│ 数据复用率     │    1     │BLOCK_SIZE │ 提升16倍     │
└─────────────────┴──────────┴───────────┴──────────────┘
```

## 代码核心部分

```cuda
template <unsigned int BLOCKS_SIZE, unsigned int K_>
__global__ void gpu_sgemm(float* A, float* B, float* C, 
                          const int M, const int N, const int K)
{
    // 声明共享内存
    __shared__ float A_shared[BLOCKS_SIZE][K_];
    __shared__ float B_shared[K_][BLOCKS_SIZE];
    
    int m = blockIdx.y * blockDim.y + threadIdx.y;
    int n = blockIdx.x * blockDim.x + threadIdx.x;
    
    // 并行加载数据到共享内存
    for(int s = 0; s < K_; s += blockDim.x) {
        int k_idx = threadIdx.x + s;
        
        // 加载A矩阵数据
        if (m < M && k_idx < K) {
            A_shared[threadIdx.y][k_idx] = A[m * K + k_idx];
        } else {
            A_shared[threadIdx.y][k_idx] = 0.0f;
        }
        
        // 加载B矩阵数据  
        int k_row = threadIdx.y + s;
        if (k_row < K && n < N) {
            B_shared[k_row][threadIdx.x] = B[k_row * N + n];
        } else {
            B_shared[k_row][threadIdx.x] = 0.0f;
        }
    }
    __syncthreads();  // 确保所有数据加载完成

    // 计算阶段：从共享内存读取数据
    if (m < M && n < N) {
        float temp = 0.0f;
        for (int k = 0; k < K; ++k) {
            temp += A_shared[threadIdx.y][k] * B_shared[k][threadIdx.x];
        }
        C[m * N + n] = temp;  // 写入结果
    }
}
```

## 算法复杂度

```
时间复杂度: O(M×N×K / P), P为并行线程数
空间复杂度: O(BLOCK_SIZE × K) - 共享内存使用量
同步次数: 1 (一次__syncthreads__)
全局内存访问: O(M×K + K×N + M×N)
共享内存访问: O(M×N×K)
```

## 适用场景

1. **中等规模矩阵**: K值不太大，适合共享内存容量
2. **性能敏感应用**: 需要比基础版本更高的性能
3. **算法学习**: 理解共享内存和数据局部性优化
4. **计算密集任务**: 算术强度较高的矩阵运算

## 限制和改进方向

### 当前限制
```
1. K维度受限: K × BLOCK_SIZE × sizeof(float) 不能超过共享内存容量
2. 静态大小: 编译时需要确定K值
3. 内存利用率: 当K不是BLOCK_SIZE的倍数时效率降低
```

### 改进方向
```
V1 → V2: 滑动窗口技术
- 固定共享内存大小
- 支持任意K值
- 动态数据加载

V1 → V3: 向量化优化  
- Float4加载指令
- 提升内存带宽利用率
- 更好的硬件资源利用
```

## 总结

V1版本引入了共享内存优化，是SGEMM优化的重要里程碑：

- **显著降低内存访问延迟**: 从400周期降低到20周期
- **大幅减少全局内存访问**: 减少约K倍的访问次数
- **提高数据复用率**: 每个数据被BLOCK_SIZE个线程复用
- **为后续优化奠定基础**: 滑动窗口和向量化技术的前提

通过引入共享内存，V1版本展示了GPU内存层次结构优化的威力，为理解更高级的优化技术提供了重要基础。
