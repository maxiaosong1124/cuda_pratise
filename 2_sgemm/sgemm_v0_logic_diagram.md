# SGEMM V0 - 全局内存版本 计算逻辑图

## 核心算法
**目标**：计算矩阵乘法 C = A × B，其中 A(M×K)，B(K×N)，C(M×N)

## 假设参数
- 矩阵A: 4×4, 矩阵B: 4×4, 矩阵C: 4×4  
- BLOCK_SIZE = 2 (为了简化图示)
- Grid: (2×2), Block: (2×2)

## 线程组织结构

### Grid和Block布局
```
Grid (2×2):               Block (2×2):
┌─────┬─────┐            ┌─────┬─────┐
│Block│Block│            │T(0,0)│T(0,1)│
│(0,0)│(0,1)│            │     │     │
├─────┼─────┤            ├─────┼─────┤
│Block│Block│            │T(1,0)│T(1,1)│
│(1,0)│(1,1)│            │     │     │
└─────┴─────┘            └─────┴─────┘
```

### 线程到矩阵元素的映射
```
每个线程计算C矩阵的一个元素:

Block(0,0)的线程:          Block(0,1)的线程:
T(0,0) → C[0][0]          T(0,0) → C[0][2]  
T(0,1) → C[0][1]          T(0,1) → C[0][3]
T(1,0) → C[1][0]          T(1,0) → C[1][2]
T(1,1) → C[1][1]          T(1,1) → C[1][3]

Block(1,0)的线程:          Block(1,1)的线程:
T(0,0) → C[2][0]          T(0,0) → C[2][2]
T(0,1) → C[2][1]          T(0,1) → C[2][3]
T(1,0) → C[3][0]          T(1,0) → C[3][2]
T(1,1) → C[3][1]          T(1,1) → C[3][3]
```

## 计算过程详解

### 以计算C[0][0]为例 (由Block(0,0)的T(0,0)负责)

#### 初始化阶段
```
线程T(0,0): m=0, n=0, temp=0.0f
目标: 计算 C[0][0] = A[0][0]*B[0][0] + A[0][1]*B[1][0] + A[0][2]*B[2][0] + A[0][3]*B[3][0]
```

#### 循环计算 (K=4次迭代)
```
k=0: 从全局内存读取 A[0*K+0] = A[0][0], B[0*N+0] = B[0][0]
     temp += A[0][0] * B[0][0]
     
k=1: 从全局内存读取 A[0*K+1] = A[0][1], B[1*N+0] = B[1][0]  
     temp += A[0][1] * B[1][0]
     
k=2: 从全局内存读取 A[0*K+2] = A[0][2], B[2*N+0] = B[2][0]
     temp += A[0][2] * B[2][0]
     
k=3: 从全局内存读取 A[0*K+3] = A[0][3], B[3*N+0] = B[3][0]
     temp += A[0][3] * B[3][0]
```

#### 写入结果
```
C[0*N+0] = C[0][0] = temp
```

## 内存访问模式分析

### 矩阵A的访问模式 (行主序)
```
线程访问的A矩阵行:
Row 0: T(0,0), T(0,1) 在不同block中都会访问 → A[0][0], A[0][1], A[0][2], A[0][3]
Row 1: T(1,0), T(1,1) 在不同block中都会访问 → A[1][0], A[1][1], A[1][2], A[1][3]
Row 2: T(0,0), T(0,1) 在下方block中访问     → A[2][0], A[2][1], A[2][2], A[2][3]
Row 3: T(1,0), T(1,1) 在下方block中访问     → A[3][0], A[3][1], A[3][2], A[3][3]

重复读取: 每个A[i][j]被读取N次 (每一列的计算都需要)
```

### 矩阵B的访问模式 (列主序)  
```
线程访问的B矩阵列:
Col 0: T(0,0), T(1,0) 在不同block中都会访问 → B[0][0], B[1][0], B[2][0], B[3][0]
Col 1: T(0,1), T(1,1) 在不同block中都会访问 → B[0][1], B[1][1], B[2][1], B[3][1]  
Col 2: T(0,0), T(1,0) 在右方block中访问     → B[0][2], B[1][2], B[2][2], B[3][2]
Col 3: T(0,1), T(1,1) 在右方block中访问     → B[0][3], B[1][3], B[2][3], B[3][3]

重复读取: 每个B[i][j]被读取M次 (每一行的计算都需要)
```

### 全局内存访问统计
```
对于M×N×K的矩阵乘法:
- A矩阵读取次数: M×N×K 次 (每个元素被读取N次)
- B矩阵读取次数: M×N×K 次 (每个元素被读取M次)  
- C矩阵写入次数: M×N 次 (每个元素写入1次)
- 总内存访问: 2×M×N×K + M×N 次
```

## 算法特点分析

### 执行流程
```
1. 每个线程计算C矩阵的一个元素
2. 线程(m,n)负责计算C[m][n] 
3. 通过K次迭代完成内积计算
4. 每次迭代从全局内存读取A和B的对应元素
5. 累加结果并写入全局内存
```

### 性能特点

#### 优点
- **实现简单**: 逻辑清晰，易于理解和调试
- **内存访问直观**: 直接的全局内存访问模式
- **无同步开销**: 不需要线程间同步

#### 缺点  
- **全局内存延迟高**: 每次计算都需要访问高延迟的全局内存
- **数据重复读取**: 同一数据被多个线程重复读取，浪费内存带宽
- **缓存效率低**: 无法有效利用共享内存的低延迟特性

### 内存访问分析

```
总内存访问量统计:
┌──────────────┬─────────────┬──────────────┐
│   操作类型   │  访问次数   │   数据复用   │
├──────────────┼─────────────┼──────────────┤
│ A矩阵读取    │  M×N×K     │ 每个元素读N次 │
│ B矩阵读取    │  M×N×K     │ 每个元素读M次 │  
│ C矩阵写入    │   M×N      │ 每个元素写1次 │
└──────────────┴─────────────┴──────────────┘

内存带宽利用率: 较低 (大量重复访问)
算术强度: 2×K / (2×K+1) ≈ 1 (接近内存密集型)
```

## 代码核心部分

```cuda
__global__ void gpu_sgemm(float* A, float* B, float* C, 
                          const int M, const int N, const int K)
{
    // 计算线程对应的输出位置
    int m = blockIdx.y * blockDim.y + threadIdx.y;  // 行索引
    int n = blockIdx.x * blockDim.x + threadIdx.x;  // 列索引

    if (m < M && n < N)  // 边界检查
    {
        float temp = 0.0f;  // 累加器初始化
        
        // 内积计算循环
        for (int k = 0; k < K; ++k)  
        {
            // 从全局内存读取并累加
            temp += A[m * K + k] * B[k * N + n];
        }
        
        // 写入结果到全局内存
        C[m * N + n] = temp;  
    }
}
```

## 算法复杂度

```
时间复杂度: O(M×N×K / P), P为并行线程数
空间复杂度: O(1) - 仅使用寄存器
同步次数: 0 (无需线程同步)
内存访问: O(M×N×K) - 每个线程访问2K+1次全局内存
```

## 适用场景

1. **学习目的**: 理解CUDA并行编程基础概念
2. **算法验证**: 作为复杂优化版本的正确性对比基准
3. **小规模矩阵**: 当矩阵较小时，优化收益不明显
4. **原型开发**: 快速实现和测试矩阵乘法功能

## 优化方向预览

这个基础版本为后续优化奠定了基础：

```
V0 (当前版本)
↓
V1: 引入共享内存 → 减少全局内存访问
↓  
V2: 滑动窗口技术 → 支持任意矩阵大小
↓
V3: 向量化加载 → 提升内存带宽利用率
```

## 总结

V0版本是SGEMM优化系列的起点，虽然性能不高，但为理解矩阵乘法的并行化思路和后续优化技术提供了重要基础。它展示了：

- GPU并行计算的基本编程模式
- 矩阵乘法的算法映射方法  
- 内存访问模式对性能的影响
- 优化空间和改进方向

通过分析这个版本的性能瓶颈，我们可以更好地理解为什么需要共享内存、数据分块等优化技术。
